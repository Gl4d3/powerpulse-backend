2025-08-29 10:25:11,028 - main - INFO - --- PowerPulse Analytics Backend Starting Up ---
2025-08-29 10:25:11,028 - main - INFO - Initializing database...
2025-08-29 10:25:11,036 - main - INFO - Database initialized.
2025-08-29 10:25:24,569 - services.file_service_optimized - INFO - Starting universal processing for upload_id: 137f94bc-94b5-448b-b870-d57fbceb5a64...
2025-08-29 10:25:24,573 - services.file_service_optimized - INFO - Detected pre-grouped JSON object format.
2025-08-29 10:25:24,575 - services.progress_tracker - INFO - Started tracking upload 137f94bc-94b5-448b-b870-d57fbceb5a64 with 20 conversations
2025-08-29 10:25:24,576 - services.progress_tracker - INFO - Upload 137f94bc-94b5-448b-b870-d57fbceb5a64: 0.0% - filtering_conversations
2025-08-29 10:25:24,592 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6173bd56f751bf0740f105c6...
2025-08-29 10:25:24,817 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6173bea0d99d10108c3abefb...
2025-08-29 10:25:24,894 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6173bfcb48774dd4690addb1...
2025-08-29 10:25:25,009 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6173c0012e6c965da961c10a...
2025-08-29 10:25:25,037 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 61745b1c9f54ec7f889910f1...
2025-08-29 10:25:25,100 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 61751db99b8246ed5141064a...
2025-08-29 10:25:25,167 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6175866910aabac8ed4ebcdf...
2025-08-29 10:25:25,187 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6175b85b66d966883cb3f71d...
2025-08-29 10:25:25,245 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 617640bdf2041cef612e5109...
2025-08-29 10:25:25,280 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 61767b0e33e3da4879eb8584...
2025-08-29 10:25:25,317 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6176f7180bb24f35959dc5f3...
2025-08-29 10:25:25,368 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6177fdb5966fdf6741c3310a...
2025-08-29 10:25:25,398 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6177ff5015107648604fc329...
2025-08-29 10:25:25,435 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 617806724f104ac65d9f75c6...
2025-08-29 10:25:25,482 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 61781fcdbab5b2dddd96b4fc...
2025-08-29 10:25:25,598 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 617823c3dd261102ee87dc71...
2025-08-29 10:25:25,642 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 61782619a6c2f29dca7cc578...
2025-08-29 10:25:25,665 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6178279a27c50e3c7e2c78de...
2025-08-29 10:25:25,699 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6178279ec7a2bef471e10342...
2025-08-29 10:25:25,747 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 617852f86017fdd615f2f37c...
2025-08-29 10:25:25,768 - services.file_service_optimized - INFO - Creating records for 20 conversations in memory...
2025-08-29 10:25:25,774 - services.batch_service - INFO - Created 2 batches from 31 daily analysis objects with a batch size of 20.
2025-08-29 10:25:25,774 - services.file_service_optimized - INFO - Splitting work into 2 batches.
2025-08-29 10:25:26,725 - services.job_service - INFO - Created 2 jobs for upload 137f94bc-94b5-448b-b870-d57fbceb5a64
2025-08-29 10:25:26,726 - services.file_service_optimized - INFO - Starting AI analysis for 2 jobs...
2025-08-29 10:25:28,100 - services.job_service - INFO - Starting Job 311 for Upload 137f94bc-94b5-448b-b870-d57fbceb5a64...
2025-08-29 10:25:28,112 - services.gemini_service - INFO - --- Preparing to call Gemini API for 20 daily analyses. ---
2025-08-29 10:25:28,333 - services.job_service - INFO - Starting Job 312 for Upload 137f94bc-94b5-448b-b870-d57fbceb5a64...
2025-08-29 10:25:28,339 - services.gemini_service - INFO - --- Preparing to call Gemini API for 11 daily analyses. ---
2025-08-29 10:25:28,950 - services.gemini_service - WARNING - Gemini call failed (attempt 1), retrying in 0.5s: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:25:29,534 - services.gemini_service - WARNING - Gemini call failed (attempt 1), retrying in 0.5s: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:25:29,695 - services.gemini_service - WARNING - Gemini call failed (attempt 2), retrying in 1.0s: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:25:30,279 - services.gemini_service - WARNING - Gemini call failed (attempt 2), retrying in 1.0s: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:25:30,941 - services.gemini_service - ERROR - Gemini call failed after 3 attempts: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:25:30,942 - services.gemini_service - ERROR - --- Gemini API call failed catastrophically after retries. Using fallbacks. ---
Traceback (most recent call last):
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 35, in analyze_daily_analyses_batch
    response, usage_metadata = await self._call_gemini_with_retry(prompt)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 143, in _call_gemini_with_retry
    response = await loop.run_in_executor(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        None, lambda: self.model.generate_content(prompt))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.2032.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 144, in <lambda>
    None, lambda: self.model.generate_content(prompt))
                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:25:30,979 - services.job_service - WARNING - Job 312 completed with status: FAILED (AI analysis fallback)
2025-08-29 10:25:31,017 - services.job_service - ERROR - Batch (Job 312) finished with status: failed
2025-08-29 10:25:31,517 - services.gemini_service - ERROR - Gemini call failed after 3 attempts: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:25:31,520 - services.gemini_service - ERROR - --- Gemini API call failed catastrophically after retries. Using fallbacks. ---
Traceback (most recent call last):
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 35, in analyze_daily_analyses_batch
    response, usage_metadata = await self._call_gemini_with_retry(prompt)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 143, in _call_gemini_with_retry
    response = await loop.run_in_executor(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        None, lambda: self.model.generate_content(prompt))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.2032.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 144, in <lambda>
    None, lambda: self.model.generate_content(prompt))
                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:25:31,533 - services.job_service - WARNING - Job 311 completed with status: FAILED (AI analysis fallback)
2025-08-29 10:25:31,562 - services.job_service - ERROR - Batch (Job 311) finished with status: failed
2025-08-29 10:25:31,639 - services.file_service_optimized - ERROR - Error processing file: (sqlite3.IntegrityError) UNIQUE constraint failed: processed_chats.fb_chat_id
[SQL: INSERT INTO processed_chats (fb_chat_id, message_count) VALUES (?, ?) RETURNING id, processed_at]
[parameters: ('6173bea0d99d10108c3abefb', 14)]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
Traceback (most recent call last):
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~^
        cursor,
        ^^^^^^^
    ...<2 lines>...
        context,
        ^^^^^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\default.py", line 951, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlite3.IntegrityError: UNIQUE constraint failed: processed_chats.fb_chat_id

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\proj-d\PowerPulse\services\file_service_optimized.py", line 131, in process_grouped_chats_json
    db.commit()
    ~~~~~~~~~^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2032, in commit
    trans.commit(_to_root=True)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "<string>", line 2, in commit
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 1313, in commit
    self._prepare_impl()
    ~~~~~~~~~~~~~~~~~~^^
  File "<string>", line 2, in _prepare_impl
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 1288, in _prepare_impl
    self.session.flush()
    ~~~~~~~~~~~~~~~~~~^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 4345, in flush
    self._flush(objects)
    ~~~~~~~~~~~^^^^^^^^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 4480, in _flush
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 4441, in _flush
    flush_context.execute()
    ~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\unitofwork.py", line 466, in execute
    rec.execute(self)
    ~~~~~~~~~~~^^^^^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self.mapper,
        ^^^^^^^^^^^^
        uow.states_for_mapper_hierarchy(self.mapper, False, False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        uow,
        ^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\persistence.py", line 93, in save_obj
    _emit_insert_statements(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        base_mapper,
        ^^^^^^^^^^^^
    ...<3 lines>...
        insert,
        ^^^^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\persistence.py", line 1143, in _emit_insert_statements
    result = connection.execute(
        statement, multiparams, execution_options=execution_options
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1419, in execute
    return meth(
        self,
        distilled_parameters,
        execution_options or NO_OPTIONS,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\sql\elements.py", line 526, in _execute_on_connection
    return connection._execute_clauseelement(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, distilled_params, execution_options
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
        dialect,
    ...<8 lines>...
        cache_hit=cache_hit,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1844, in _execute_context
    return self._exec_insertmany_context(dialect, context)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2126, in _exec_insertmany_context
    self._handle_dbapi_exception(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        e,
        ^^
    ...<4 lines>...
        is_sub_exec=True,
        ^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~^
        cursor,
        ^^^^^^^
    ...<2 lines>...
        context,
        ^^^^^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\default.py", line 951, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.IntegrityError: (sqlite3.IntegrityError) UNIQUE constraint failed: processed_chats.fb_chat_id
[SQL: INSERT INTO processed_chats (fb_chat_id, message_count) VALUES (?, ?) RETURNING id, processed_at]
[parameters: ('6173bea0d99d10108c3abefb', 14)]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-08-29 10:25:31,679 - services.progress_tracker - INFO - Upload 137f94bc-94b5-448b-b870-d57fbceb5a64 failed in 7.1s
2025-08-29 10:29:39,594 - services.file_service_optimized - INFO - Starting universal processing for upload_id: 41edbdcc-0c3d-4ec1-8876-9b6e4974898f...
2025-08-29 10:29:39,598 - services.file_service_optimized - INFO - Detected pre-grouped JSON object format.
2025-08-29 10:29:39,599 - services.progress_tracker - INFO - Started tracking upload 41edbdcc-0c3d-4ec1-8876-9b6e4974898f with 20 conversations
2025-08-29 10:29:39,601 - services.progress_tracker - INFO - Upload 41edbdcc-0c3d-4ec1-8876-9b6e4974898f: 0.0% - filtering_conversations
2025-08-29 10:29:39,609 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6173bd56f751bf0740f105c6...
2025-08-29 10:29:39,870 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6173bea0d99d10108c3abefb...
2025-08-29 10:29:39,956 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6173bfcb48774dd4690addb1...
2025-08-29 10:29:40,070 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6173c0012e6c965da961c10a...
2025-08-29 10:29:40,102 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 61745b1c9f54ec7f889910f1...
2025-08-29 10:29:40,153 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 61751db99b8246ed5141064a...
2025-08-29 10:29:40,207 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6175866910aabac8ed4ebcdf...
2025-08-29 10:29:40,228 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6175b85b66d966883cb3f71d...
2025-08-29 10:29:40,281 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 617640bdf2041cef612e5109...
2025-08-29 10:29:40,306 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 61767b0e33e3da4879eb8584...
2025-08-29 10:29:40,328 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6176f7180bb24f35959dc5f3...
2025-08-29 10:29:40,369 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6177fdb5966fdf6741c3310a...
2025-08-29 10:29:40,393 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6177ff5015107648604fc329...
2025-08-29 10:29:40,421 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 617806724f104ac65d9f75c6...
2025-08-29 10:29:40,457 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 61781fcdbab5b2dddd96b4fc...
2025-08-29 10:29:40,525 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 617823c3dd261102ee87dc71...
2025-08-29 10:29:40,566 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 61782619a6c2f29dca7cc578...
2025-08-29 10:29:40,594 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6178279a27c50e3c7e2c78de...
2025-08-29 10:29:40,634 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 6178279ec7a2bef471e10342...
2025-08-29 10:29:40,685 - services.file_service_optimized - INFO - Force reprocess: Deleting existing conversation data for 617852f86017fdd615f2f37c...
2025-08-29 10:29:40,706 - services.file_service_optimized - INFO - Creating records for 20 conversations in memory...
2025-08-29 10:29:40,714 - services.batch_service - INFO - Created 2 batches from 31 daily analysis objects with a batch size of 20.
2025-08-29 10:29:40,714 - services.file_service_optimized - INFO - Splitting work into 2 batches.
2025-08-29 10:29:41,387 - services.job_service - INFO - Created 2 jobs for upload 41edbdcc-0c3d-4ec1-8876-9b6e4974898f
2025-08-29 10:29:41,387 - services.file_service_optimized - INFO - Starting AI analysis for 2 jobs...
2025-08-29 10:29:42,690 - services.job_service - INFO - Starting Job 313 for Upload 41edbdcc-0c3d-4ec1-8876-9b6e4974898f...
2025-08-29 10:29:42,697 - services.gemini_service - INFO - --- Preparing to call Gemini API for 20 daily analyses. ---
2025-08-29 10:29:42,875 - services.job_service - INFO - Starting Job 314 for Upload 41edbdcc-0c3d-4ec1-8876-9b6e4974898f...
2025-08-29 10:29:42,885 - services.gemini_service - INFO - --- Preparing to call Gemini API for 11 daily analyses. ---
2025-08-29 10:29:43,781 - services.gemini_service - WARNING - Gemini call failed (attempt 1), retrying in 0.5s: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:29:43,849 - services.gemini_service - WARNING - Gemini call failed (attempt 1), retrying in 0.5s: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:29:44,482 - services.gemini_service - WARNING - Gemini call failed (attempt 2), retrying in 1.0s: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:29:45,092 - services.gemini_service - WARNING - Gemini call failed (attempt 2), retrying in 1.0s: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:29:45,667 - services.gemini_service - ERROR - Gemini call failed after 3 attempts: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:29:45,672 - services.gemini_service - ERROR - --- Gemini API call failed catastrophically after retries. Using fallbacks. ---
Traceback (most recent call last):
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 35, in analyze_daily_analyses_batch
    response, usage_metadata = await self._call_gemini_with_retry(prompt)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 143, in _call_gemini_with_retry
    response = await loop.run_in_executor(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        None, lambda: self.model.generate_content(prompt))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.2032.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 144, in <lambda>
    None, lambda: self.model.generate_content(prompt))
                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:29:45,692 - services.job_service - WARNING - Job 314 completed with status: FAILED (AI analysis fallback)
2025-08-29 10:29:45,714 - services.job_service - ERROR - Batch (Job 314) finished with status: failed
2025-08-29 10:29:46,328 - services.gemini_service - ERROR - Gemini call failed after 3 attempts: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:29:46,331 - services.gemini_service - ERROR - --- Gemini API call failed catastrophically after retries. Using fallbacks. ---
Traceback (most recent call last):
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 35, in analyze_daily_analyses_batch
    response, usage_metadata = await self._call_gemini_with_retry(prompt)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 143, in _call_gemini_with_retry
    response = await loop.run_in_executor(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        None, lambda: self.model.generate_content(prompt))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.2032.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\thread.py", line 59, in run
    result = self.fn(*self.args, **self.kwargs)
  File "D:\proj-d\PowerPulse\services\gemini_service.py", line 144, in <lambda>
    None, lambda: self.model.generate_content(prompt))
                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1086548496648'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "europe-west1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/1086548496648"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-08-29 10:29:46,350 - services.job_service - WARNING - Job 313 completed with status: FAILED (AI analysis fallback)
2025-08-29 10:29:46,364 - services.job_service - ERROR - Batch (Job 313) finished with status: failed
2025-08-29 10:29:46,394 - services.file_service_optimized - ERROR - Error processing file: (sqlite3.IntegrityError) UNIQUE constraint failed: processed_chats.fb_chat_id
[SQL: INSERT INTO processed_chats (fb_chat_id, message_count) VALUES (?, ?) RETURNING id, processed_at]
[parameters: ('6173bd56f751bf0740f105c6', 36)]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
Traceback (most recent call last):
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~^
        cursor,
        ^^^^^^^
    ...<2 lines>...
        context,
        ^^^^^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\default.py", line 951, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlite3.IntegrityError: UNIQUE constraint failed: processed_chats.fb_chat_id

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\proj-d\PowerPulse\services\file_service_optimized.py", line 131, in process_grouped_chats_json
    db.commit()
    ~~~~~~~~~^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2032, in commit
    trans.commit(_to_root=True)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "<string>", line 2, in commit
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 1313, in commit
    self._prepare_impl()
    ~~~~~~~~~~~~~~~~~~^^
  File "<string>", line 2, in _prepare_impl
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 1288, in _prepare_impl
    self.session.flush()
    ~~~~~~~~~~~~~~~~~~^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 4345, in flush
    self._flush(objects)
    ~~~~~~~~~~~^^^^^^^^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 4480, in _flush
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\session.py", line 4441, in _flush
    flush_context.execute()
    ~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\unitofwork.py", line 466, in execute
    rec.execute(self)
    ~~~~~~~~~~~^^^^^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\unitofwork.py", line 642, in execute
    util.preloaded.orm_persistence.save_obj(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self.mapper,
        ^^^^^^^^^^^^
        uow.states_for_mapper_hierarchy(self.mapper, False, False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        uow,
        ^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\persistence.py", line 93, in save_obj
    _emit_insert_statements(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        base_mapper,
        ^^^^^^^^^^^^
    ...<3 lines>...
        insert,
        ^^^^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\orm\persistence.py", line 1143, in _emit_insert_statements
    result = connection.execute(
        statement, multiparams, execution_options=execution_options
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1419, in execute
    return meth(
        self,
        distilled_parameters,
        execution_options or NO_OPTIONS,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\sql\elements.py", line 526, in _execute_on_connection
    return connection._execute_clauseelement(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, distilled_params, execution_options
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1641, in _execute_clauseelement
    ret = self._execute_context(
        dialect,
    ...<8 lines>...
        cache_hit=cache_hit,
    )
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1844, in _execute_context
    return self._exec_insertmany_context(dialect, context)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2126, in _exec_insertmany_context
    self._handle_dbapi_exception(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        e,
        ^^
    ...<4 lines>...
        is_sub_exec=True,
        ^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~^
        cursor,
        ^^^^^^^
    ...<2 lines>...
        context,
        ^^^^^^^^
    )
    ^
  File "D:\proj-d\PowerPulse\venv\Lib\site-packages\sqlalchemy\engine\default.py", line 951, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.IntegrityError: (sqlite3.IntegrityError) UNIQUE constraint failed: processed_chats.fb_chat_id
[SQL: INSERT INTO processed_chats (fb_chat_id, message_count) VALUES (?, ?) RETURNING id, processed_at]
[parameters: ('6173bd56f751bf0740f105c6', 36)]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2025-08-29 10:29:46,407 - services.progress_tracker - INFO - Upload 41edbdcc-0c3d-4ec1-8876-9b6e4974898f failed in 6.8s
